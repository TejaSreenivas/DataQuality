{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fm1-zoW5dwJx"
   },
   "source": [
    "# Notes\n",
    "*  Skewed Distribution also makes for large data??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFXKg73pXcMT"
   },
   "source": [
    "# **Documentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r6nZZk-XXgHL"
   },
   "source": [
    "## Index - Level 1 API (algos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uVUdJkcGXj3e"
   },
   "source": [
    "### 1. Simple gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wVJITDt4Xt--"
   },
   "source": [
    "The first evaluation metric is Simple univariant gaussian distribution, <br/>\n",
    "1.  Fuction: fit_gauss(): returns the mean and std for a normal distribution modeled on particular column\n",
    "2. is_anomaly(col, val, param): returns (flag, plot),\n",
    "    * col - column name\n",
    "    * val - value of the column for a row\n",
    "    * param - dict containing mean and std for that the column \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSe26TkldHjo"
   },
   "source": [
    "### 2. Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahT3G5gldPwV"
   },
   "source": [
    "1. fit_isolation_forest(self, data): applies isolation forest to the data and returns the classifier\n",
    "    * Isolation forest is applied for the entire data\n",
    "    * Isolation forest scores are in the range of -0.5 to +0.5, the greater the score the less the anomalous (Opposite of the original paper) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8noMooga0uB"
   },
   "source": [
    "## Index - Level 2 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oO1iERpLa8pH"
   },
   "source": [
    "### 1. Column level anomaly detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvbusY-xbraV"
   },
   "source": [
    "1. compute_columnar_anomaly(self, data, anomalous_rows ): Disaplays all the anomalous columns for all potential anomalous_rows\n",
    "    * data - complete data (or partial data)\n",
    "    * anomalous_rows - rows that the function needs to compute columnar anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hX53nRfLXY-q"
   },
   "source": [
    "#CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRjrmQYaX98x"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import cv2\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from os.path import join\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from scipy.stats import norm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6afC9JYXOFK_"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3eZLRsmBX2zg"
   },
   "outputs": [],
   "source": [
    "# NY yellow taxi data\n",
    "data = pd.read_csv(join(os.getcwd(),'drive','My Drive', 'datasets', 'table','yellow_tripdata_2019-01.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Plnjwb5pPvMY"
   },
   "outputs": [],
   "source": [
    "def test(**kwargs):\n",
    "    print('first' in kwargs.keys())\n",
    "test(second = 10)\n",
    "data.congestion_surcharge[~np.isnan(data.congestion_surcharge)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WiVEwpenbWj8"
   },
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iVRmmJVG9UXe"
   },
   "outputs": [],
   "source": [
    "def get_img_from_fig(fig, dpi=150):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=dpi, bbox_inches = 'tight')\n",
    "    buf.seek(0)\n",
    "    img_arr = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
    "    buf.close()\n",
    "    img = cv2.imdecode(img_arr, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "def print_nplots(plots):\n",
    "    n = len(plots)\n",
    "    fig=plt.figure(figsize=(9, 6*n))\n",
    "    for i in range(len(plots)):\n",
    "        fig.add_subplot(n,1,i+1)\n",
    "        plt.imshow(plots[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zxm2IJYolQFj"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_gauss(col = 'column name', mu=998.8, sigma=73.10, sensitivity = 1,val=1120):\n",
    "    \n",
    "    z1 = mu - sigma*sensitivity\n",
    "    z2 = mu + sigma*sensitivity\n",
    "    x = np.arange(z1, z2, sigma/100) \n",
    "    # plot range x1, x2\n",
    "    if val>mu:\n",
    "        x2 = max(mu + sigma* max(sensitivity, 4), val)\n",
    "        x1 = mu - sigma*max(sensitivity, 4)\n",
    "    else:\n",
    "        x1 = min(mu - sigma * max(sensitivity, 4), val)\n",
    "        x2 = mu + sigma*max(sensitivity, 4)\n",
    "    x_all = np.arange(x1, x2, sigma/100)\n",
    "    # print(x1,x2)\n",
    "    # print(x.shape)\n",
    "    # print(x_all.shape)\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    y = norm.pdf(x,mu,sigma)\n",
    "    # print(y.shape)\n",
    "    y_all = norm.pdf(x_all,mu,sigma)\n",
    "    # print(y_all.shape)\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    ax.plot(x_all, y_all)\n",
    "    ax.fill_between(x,y,0, alpha=0.3, color='g')\n",
    "    ax.fill_between(x_all,y_all,0, alpha=0.1)\n",
    "    ax.scatter(val, norm.pdf(val,mu,sigma), s=100,c='r',marker = 'o', label = 'Position of Anomaly')\n",
    "    # ax.set_xlim([-4,4])\n",
    "    ax.set_xlabel('Gaussian distribution')\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_title(col)\n",
    "    plt.legend()\n",
    "    plt.close(fig)\n",
    "    # plt.savefig('normal_curve.png', dpi=72, bbox_inches='tight')\n",
    "    # plt.show()\n",
    "    return get_img_from_fig(fig)\n",
    "\n",
    "# l = []\n",
    "# l.append(plot_gauss())\n",
    "# l.append(plot_gauss(mu=10,sigma=2,val = 3))\n",
    "# # plot_gauss(mu = 100.0,sigma = 2.0, val=110)\n",
    "# # plot_gauss()\n",
    "# plt.figure(figsize=(10,15))\n",
    "# plt.subplot(211)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(l[0])\n",
    "# plt.subplot(212)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(l[1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTMaRotgisQD"
   },
   "outputs": [],
   "source": [
    "x = [-2.1, -1,  4.3]\n",
    "y = [3,  1.1,  0.12]\n",
    "X = np.stack((x, y), axis=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "coT2TRPdOFmL"
   },
   "outputs": [],
   "source": [
    "class ColumnMeta:\n",
    "    # assigning meta data for columns\n",
    "    def __init__(self, **kwarg):\n",
    "        self.name = kwarg['name']\n",
    "        self.dtype = kwarg['dtype']\n",
    "        self.gauss_param = dict()\n",
    "    def summary(self):\n",
    "        print(\"__________________________\")\n",
    "        print(\"Column parameters: \")\n",
    "        print(\"Column name  :\",self.name)\n",
    "        print(\"Data type    :\",self.dtype)\n",
    "        print(\"Gaussian para:\",self.gauss_param)\n",
    "\n",
    "\n",
    "class NumericOutlier:\n",
    "    def summary(self, columns):\n",
    "        for c in columns:\n",
    "            if np.issubdtype(self.columns[c].dtype, np.number):\n",
    "                self.columns[c].summary()\n",
    "    \n",
    "    def fit_gauss(self,data):\n",
    "        mean,std=norm.fit(data)\n",
    "        return {\"mean\": mean, \"std\":std, 'sensitivity':2}\n",
    "\n",
    "    def is_gauss_anomaly(self, col, val, param):\n",
    "        # print(val)\n",
    "        if ( abs(val-param['mean']) > param['sensitivity'] * param['std'] ):\n",
    "            return True, plot_gauss(col, param['mean'], param['std'], param['sensitivity'], val)\n",
    "        else:\n",
    "            return False, 0\n",
    "    \n",
    "    def multivariate_normal(self, x):\n",
    "        \"\"\"pdf of the multivariate normal distribution.\"\"\"\n",
    "        d = self.Multivariant_Gauss_param['d']\n",
    "        mean = self.Multivariant_Gauss_param['mean']\n",
    "        covariance = self.Multivariant_Gauss_param['cov']\n",
    "        x_m = x - mean\n",
    "        return (1. / (np.sqrt((2 * np.pi)**d * np.linalg.det(covariance))) * \n",
    "                np.exp(-(np.linalg.solve(covariance, x_m).T.dot(x_m)) / 2))\n",
    "        \n",
    "    def fit_isolation_forest(self, data):\n",
    "        from sklearn.ensemble import IsolationForest\n",
    "        clf = IsolationForest(random_state=0).fit(data.dropna())\n",
    "        return clf\n",
    "\n",
    "    def row_filtering(self, data):\n",
    "        query_data = data[self.numeric_list].dropna().to_numpy()\n",
    "        anomaly_score = dict()\n",
    "        print(\"computing isolation forest scores....\", end='')\n",
    "        anomaly_score['isolation_forest'] = self.isolation_forest_clf.score_samples(query_data)\n",
    "        print('completed!')\n",
    "\n",
    "        print(\"computing multivariant gaussian scores..\")\n",
    "        probs = []\n",
    "        for x in tqdm_notebook(query_data, desc = 'rows:'):\n",
    "            probs.append(self.multivariate_normal(x))\n",
    "        anomaly_score['multivariant_gauss'] = np.array(probs)\n",
    "        # calculate net anomaly score\n",
    "        net_anomaly = np.zeros((query_data.shape[0]), np.float32)\n",
    "        for key in self.row_level_ensemble_weight.keys():\n",
    "            # rescale score\n",
    "            scaled_score = (anomaly_score[key] - anomaly_score[key].min())/(anomaly_score[key].max() - anomaly_score[key].min())\n",
    "            weighted_score = scaled_score * self.row_level_ensemble_weight[key]\n",
    "            net_anomaly+=weighted_score\n",
    "        anomaly_list = np.argsort(net_anomaly)[:int(self.n_percent*net_anomaly.shape[0])]\n",
    "        # using Multivariant Normal distribution\n",
    "        return anomaly_list\n",
    "\n",
    "    def Query(self, data):\n",
    "        # detect outlier pipline \n",
    "        anomaly_list = self.row_filtering(data)\n",
    "        row_col = self.compute_columnar_anomaly(data, anomaly_list)\n",
    "        return anomaly_list,row_col\n",
    "    \n",
    "    def compute_columnar_anomaly(self, data, anomalous_rows ):\n",
    "        row_cols_pairs = []\n",
    "        for row in anomalous_rows:\n",
    "            anomalous_cols = []\n",
    "            gauss_plots = []\n",
    "            for c in self.numeric_list:\n",
    "                b, plot = self.is_gauss_anomaly(c ,data.loc[row, c] ,self.columns[c].gauss_param)\n",
    "                if(b): gauss_plots.append(plot)\n",
    "            if(len(gauss_plots)==0):\n",
    "                print(\"No Anomaly found at Row: \",row)\n",
    "            else:\n",
    "                print(\"Anomaly found at following columns for row: \",row)\n",
    "                row_cols_pairs.append((row, c))\n",
    "                print_nplots(gauss_plots)\n",
    "        return row_cols_pairs\n",
    "\n",
    "    def __init__(self, data, **parameters):\n",
    "        self.columns = dict()\n",
    "        self.numeric_list = []\n",
    "        self.row_level_ensemble_weight = dict()\n",
    "        self.row_level_ensemble_weight['isolation_forest'] = 0.5\n",
    "        self.row_level_ensemble_weight['multivariant_gauss'] = 0.5\n",
    "        # top 1% anomalous data\n",
    "        self.n_percent = 0.0001\n",
    "        # parameters for multivariant gauss distribution\n",
    "        self.Multivariant_Gauss_param = dict()\n",
    "        for c in data.columns:\n",
    "            self.columns[c] = ColumnMeta(name = c, dtype = data[c].dtype)\n",
    "            # print(c)\n",
    "            if np.issubdtype(self.columns[c].dtype, np.number) and len(re.findall('ID',c))==0:\n",
    "                col = np.array(data[c])\n",
    "                self.columns[c].gauss_param = self.fit_gauss(col[~np.isnan(col)])  \n",
    "                self.numeric_list.append(c)\n",
    "                # self.columns[c].summary()\n",
    "        \n",
    "        print(\"Running Isolation forest......\",end='')\n",
    "        self.isolation_forest_clf = self.fit_isolation_forest(data[self.numeric_list].dropna())\n",
    "        print(\"completed!\")\n",
    "        \n",
    "        print(\"Running Mutivariant Gaussian distribution.....\",end='')\n",
    "        self.Multivariant_Gauss_param['d'] = len(self.numeric_list)\n",
    "        self.Multivariant_Gauss_param['mean'] = data[self.numeric_list].mean().to_numpy()\n",
    "        self.Multivariant_Gauss_param['cov'] = data[self.numeric_list].cov().to_numpy()\n",
    "        print(\"completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PJDoD2N_3f7f"
   },
   "source": [
    "### scrap space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utiMDZs04Duf"
   },
   "source": [
    "TODO\n",
    "* probability density function to figure out first n% errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4slKUTPGbD2"
   },
   "outputs": [],
   "source": [
    "test_query = data.sample(n=30).reset_index(drop=True)\n",
    "query_data = pd.DataFrame(test_query, columns = data.columns)\n",
    "query_data = query_data[detect.numeric_list].dropna().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9au3m2nvSG_"
   },
   "outputs": [],
   "source": [
    "is_score = detect.isolation_forest_clf.score_samples(query_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Ipjp__8jDnR"
   },
   "outputs": [],
   "source": [
    "(is_score[is_score<-0.5].shape[0])/is_score.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vB_Jhx5mhkv-"
   },
   "outputs": [],
   "source": [
    "probs = []\n",
    "for x in tqdm_notebook(query_data):\n",
    "    probs.append(detect.multivariate_normal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1gAZDI7wdkE"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "probs = np.array(probs)\n",
    "sns.distplot((probs-probs.min())/(probs.max()-probs.min()), hist=False, rug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apHe7G9NjAZY"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot((is_score-is_score.min())/(is_score.max()-is_score.min()), hist=False, rug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WlWXV623zsXg"
   },
   "outputs": [],
   "source": [
    "r_probs = (probs-probs.min())/(probs.max()-probs.min())\n",
    "r_isfor = (is_score-is_score.min())/(is_score.max()-is_score.min())\n",
    "final_score = r_probs*0.5+r_isfor*0.5\n",
    "rows_list = np.argsort(final_score)[:int(0.00001*final_score.shape[0])]\n",
    "rows_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EXaDphMyskt"
   },
   "outputs": [],
   "source": [
    "test_ar = np.array([11, 13, 41, 10, 2, 14, 18, 20])\n",
    "np.argsort(test_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SX7S8eagsR7R"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(probs, hist=False, rug=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMJECFb3Xk76"
   },
   "source": [
    "# TEST Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z88OqjJwXnol"
   },
   "outputs": [],
   "source": [
    "detect = NumericOutlier(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLSUOjPi-CM4"
   },
   "outputs": [],
   "source": [
    "detect.summary(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3w2mI-Z-fmIb"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SornPlsk3Xe"
   },
   "outputs": [],
   "source": [
    "data.sample(n=10).reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zLs_uT2fIlx"
   },
   "outputs": [],
   "source": [
    "test_query = []\n",
    "test_query.append([1,'2019-01-01 00:46:40', '2019-01-01 00:53:20', 3, 6.5,1,'N',141,154,1,400.0,0.5,0.5,1.65,0.0,0.3,9.95,0])\n",
    "test_query.append([1,'2019-01-01 00:46:40', '2019-01-01 00:53:20', 3, 6.5,1,'N',141,154,1,800.0,0.5,0.5,1.65,0.0,0.3,9.95,0])\n",
    "test_query = data.sample(n=10).reset_index(drop=True)\n",
    "query_data = pd.DataFrame(test_query, columns = data.columns)\n",
    "a_rows, a_row_cols = detect.Query(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "405TyQw6BYLO"
   },
   "source": [
    "# Colorize table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ola0Va4FBeSO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xc3kVr-wG3Dq"
   },
   "source": [
    "## Manage Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "V6dku3l1GHc2"
   },
   "outputs": [],
   "source": [
    "#@title Manage Sensitivity of columns\n",
    "standard_deviation = 1 #@param {type:\"slider\", min:0, max:4, step:0.1}\n",
    "column = 'fare_amount' #@param [\"VendorID\", \"passenger_count\", \"trip_distance\", \"RatecodeID\", \"PULocationID\", \"DOLocationID\", \"payment_type\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\", \"congestion_surcharge\"] {type:\"string\"}\n",
    "detect.columns[column].gauss_param['sensitivity'] = standard_deviation\n",
    "detect.Query(query_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JFXKg73pXcMT",
    "r6nZZk-XXgHL",
    "uVUdJkcGXj3e",
    "dSe26TkldHjo",
    "s8noMooga0uB",
    "oO1iERpLa8pH"
   ],
   "name": "Modules.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
